<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Jin Ye (叶锦) - Personal Website</title>
    <!-- <meta name="description" content="Jin Ye (叶锦) - PhD student in Computer Vision at Monash University">
    <meta name="keywords" content="Jin Ye, 叶锦, Computer Vision, Medical AI, Monash University"> -->
    
    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    
    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    
    <style>
        :root {
            --primary-color: #0a66c2;
            --secondary-color: #004182;
            --accent-color: #f59e0b;
            --text-primary: #1f2937;
            --text-secondary: #6b7280;
            --bg-primary: #ffffff;
            --bg-secondary: #f9fafb;
            --border-color: #e5e7eb;
            --shadow: 0 1px 3px 0 rgba(0, 0, 0, 0.1), 0 1px 2px 0 rgba(0, 0, 0, 0.06);
            --shadow-lg: 0 10px 15px -3px rgba(0, 0, 0, 0.1), 0 4px 6px -2px rgba(0, 0, 0, 0.05);
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            color: var(--text-primary);
            background-color: var(--bg-secondary);
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 0 20px;
        }

        /* Header */
        .header {
            background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
            color: white;
            padding: 2rem 0;
            margin-bottom: 2rem;
        }

        .header-content {
            display: flex;
            align-items: center;
            gap: 2rem;
            flex-wrap: wrap;
        }

        .profile-image {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            object-fit: cover;
            border: 4px solid rgba(255, 255, 255, 0.2);
            box-shadow: var(--shadow-lg);
        }

        .header-text h1 {
            font-size: 2.5rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
        }

        .header-text h2 {
            font-size: 1.25rem;
            font-weight: 500;
            margin-bottom: 1rem;
            opacity: 0.9;
        }

        .header-text p {
            font-size: 1rem;
            opacity: 0.8;
            margin-bottom: 0.5rem;
        }

        .contact-info {
            display: flex;
            gap: 1rem;
            flex-wrap: wrap;
            margin-top: 1rem;
        }

        .contact-item {
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 25px;
            backdrop-filter: blur(10px);
            transition: all 0.3s ease;
        }

        .contact-item:hover {
            background: rgba(255, 255, 255, 0.2);
            transform: translateY(-2px);
        }

        .contact-item a {
            color: white;
            text-decoration: none;
        }

        /* Navigation */
        .nav {
            background: var(--bg-primary);
            border-bottom: 1px solid var(--border-color);
            position: sticky;
            top: 0;
            z-index: 100;
            box-shadow: var(--shadow);
        }

        .nav-content {
            display: flex;
            justify-content: center;
            gap: 2rem;
            padding: 1rem 0;
        }

        .nav-item {
            color: var(--text-secondary);
            text-decoration: none;
            font-weight: 500;
            padding: 0.5rem 1rem;
            border-radius: 8px;
            transition: all 0.3s ease;
        }

        .nav-item:hover,
        .nav-item.active {
            color: var(--primary-color);
            background: var(--bg-secondary);
        }

        /* Sections */
        .section {
            background: var(--bg-primary);
            border-radius: 12px;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
            box-shadow: var(--shadow);
            border: 1px solid var(--border-color);
        }

        .section h2 {
            font-size: 1.3rem;
            font-weight: 600;
            margin-bottom: 1.2rem;
            color: var(--text-primary);
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }

        .section h2 i {
            color: var(--primary-color);
        }

        /* About */
        .about-content {
            font-size: 1rem;
            line-height: 1.6;
            color: var(--text-secondary);
        }

        /* News */
        .news-item {
            display: flex;
            align-items: center;
            gap: 1rem;
            padding: 0.8rem 0;
            border-bottom: 1px solid var(--border-color);
        }

        .news-item:last-child {
            border-bottom: none;
        }

        .news-date {
            background: var(--primary-color);
            color: white;
            padding: 0.4rem 0.8rem;
            border-radius: 20px;
            font-size: 0.8rem;
            font-weight: 500;
            white-space: nowrap;
        }

        .news-text {
            flex: 1;
            color: var(--text-secondary);
            font-size: 0.95rem;
        }

        .news-text strong {
            color: var(--text-primary);
        }

        /* Publications */
        .publication {
            padding: 0.8rem 0;
            border-bottom: 1px solid var(--border-color);
        }

        .publication:last-child {
            border-bottom: none;
        }

        .publication-content {
            width: 100%;
        }

        .publication-title {
            font-size: 1rem;
            font-weight: 600;
            color: var(--text-primary);
            margin-bottom: 0.3rem;
            line-height: 1.4;
        }

        .publication-authors {
            color: var(--text-secondary);
            margin-bottom: 0.3rem;
            font-size: 0.9rem;
        }

        .publication-venue {
            color: var(--primary-color);
            font-weight: 500;
            font-size: 0.85rem;
            background: var(--bg-secondary);
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
            border: 1px solid var(--border-color);
            display: inline-block;
            margin-right: 0.5rem;
        }

        .publication-links {
            display: flex;
            gap: 0.5rem;
            flex-wrap: wrap;
            align-items: center;
        }

        .publication-link {
            display: inline-flex;
            align-items: center;
            gap: 0.25rem;
            padding: 0.25rem 0.5rem;
            background: var(--bg-secondary);
            color: var(--text-secondary);
            text-decoration: none;
            border-radius: 4px;
            font-size: 0.7rem;
            font-weight: 500;
            transition: all 0.2s ease;
            border: 1px solid var(--border-color);
        }

        .publication-link:hover {
            background: var(--primary-color);
            color: white;
            border-color: var(--primary-color);
            transform: translateY(-1px);
        }

        /* Awards & Contests */
        .award-item,
        .contest-item {
            display: flex;
            align-items: center;
            gap: 0.8rem;
            padding: 0.8rem 0;
            border-bottom: 1px solid var(--border-color);
        }

        .award-item:last-child,
        .contest-item:last-child {
            border-bottom: none;
        }

        .award-icon,
        .contest-icon {
            width: 35px;
            height: 35px;
            background: var(--primary-color);
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            flex-shrink: 0;
        }

        .award-content,
        .contest-content {
            flex: 1;
        }

        .award-title,
        .contest-title {
            font-weight: 600;
            color: var(--text-primary);
            margin-bottom: 0.2rem;
            font-size: 0.95rem;
        }

        .award-description,
        .contest-description {
            color: var(--text-secondary);
            font-size: 0.85rem;
        }

        /* Footer */
        .footer {
            text-align: center;
            padding: 2rem 0;
            color: var(--text-secondary);
            border-top: 1px solid var(--border-color);
            margin-top: 3rem;
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            .header-content {
                flex-direction: column;
                text-align: center;
            }

            .profile-image {
                width: 120px;
                height: 120px;
            }

            .header-text h1 {
                font-size: 2rem;
            }

            .contact-info {
                justify-content: center;
            }

            .nav-content {
                flex-wrap: wrap;
                gap: 1rem;
            }

            .publication {
                flex-direction: column;
            }

            .publication-image {
                width: 100%;
                height: 200px;
            }
        }

        /* Smooth scrolling */
        html {
            scroll-behavior: smooth;
        }

        /* Loading animation */
        .loading {
            opacity: 0;
            transform: translateY(20px);
            animation: fadeInUp 0.6s ease forwards;
        }

        @keyframes fadeInUp {
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .loading:nth-child(2) { animation-delay: 0.1s; }
        .loading:nth-child(3) { animation-delay: 0.2s; }
        .loading:nth-child(4) { animation-delay: 0.3s; }
        .loading:nth-child(5) { animation-delay: 0.4s; }
    </style>
</head>
<body>
    <!-- Header -->
    <header class="header">
        <div class="container">
            <div class="header-content">
                <img src="yejin.png" alt="Jin Ye (叶锦)" class="profile-image">
                <div class="header-text">
                    <h1>Jin Ye (叶锦)</h1>
                    <h2>PhD Student in Computer Vision and Medical AI</h2>
                    <p><strong>Department of Data Science and AI, Faculty of IT, Monash University, Melbourne, Australia</strong></p>
                    <div class="contact-info">
                        <div class="contact-item">
                            <i class="fas fa-envelope"></i>
                            <a href="mailto:eugene.j.yonng@gmail.com">eugene.j.yonng@gmail.com</a>
                        </div>
                        <div class="contact-item">
                            <i class="fab fa-google"></i>
                            <a href="https://scholar.google.com/citations?user=UFBrJOAAAAAJ" target="_blank">Google Scholar</a>
                        </div>
                        <div class="contact-item">
                            <i class="fab fa-linkedin"></i>
                            <a href="https://www.linkedin.com/in/jin-ye-037a4729b/?originalSubdomain=au" target="_blank">LinkedIn</a>
                        </div>
                        <div class="contact-item">
                            <i class="fab fa-github"></i>
                            <a href="https://github.com/Yejin0111" target="_blank">GitHub</a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- Navigation -->
    <nav class="nav">
        <div class="container">
            <div class="nav-content">
                <a href="#about" class="nav-item active">About</a>
                <a href="#news" class="nav-item">News</a>
                <a href="#publications" class="nav-item">Publications</a>
                <a href="#awards" class="nav-item">Awards</a>
                <a href="#academic-activities" class="nav-item">Activities</a>
                <a href="#talks" class="nav-item">Talks</a>
            </div>
        </div>
    </nav>

    <!-- Main Content -->
    <main class="container">
        <!-- About Section -->
        <section id="about" class="section loading">
            <h2><i class="fas fa-user"></i>About Me</h2>
            <div class="about-content">
                <!-- I am a research assistant under the supervision of Prof. <a href="http://mmlab.siat.ac.cn/yuqiao/" target="_blank" style="color: var(--primary-color);">Yu Qiao</a> and Prof. <a href="https://pengxj.github.io/" target="_blank" style="color: var(--primary-color);">Xiaojiang Peng</a> at Multimedia Laboratory (MMLAB) of Shenzhen Institutes of Advanced Technology (SIAT). Before that, I got my master and bachelor from <a href="http://english.ucas.ac.cn/" target="_blank" style="color: var(--primary-color);">University of Chinese Academy of Sciences</a> and <a href="https://english.jnu.edu.cn/" target="_blank" style="color: var(--primary-color);">Jinan University (Guangzhou, China)</a>, respectively. -->
                <p>I am a PhD student at Monash University, supervised by Prof. <a href="https://jianfei-cai.github.io/" target="_blank" style="color: var(--primary-color);">Jianfei Cai</a>, A/Prof. <a href="https://www.drzchen.com/" target="_blank" style="color: var(--primary-color);">Zhaolin Chen</a>, and Dr. <a href="https://bohanzhuang.github.io/" target="_blank" style="color: var(--primary-color);">Bohan Zhuang</a>. Before starting my PhD, I was a full-time researcher at Shanghai AI Lab working with Dr. <a href="https://scholar.google.com/citations?user=Z4LgebkAAAAJ" target="_blank" style="color: var(--primary-color);">Junjun He</a> and Prof. <a href="https://scholar.google.com/citations?user=gFtI-8QAAAAJ" target="_blank" style="color: var(--primary-color);">Yu Qiao</a>. Earlier, I was a Senior R&D Engineer at Baidu collaborating with Dr. <a href="https://scholar.google.com/citations?user=R1rVRUkAAAAJ" target="_blank" style="color: var(--primary-color);">Xiao Tan</a> and Dr.  <a href="https://openreview.net/profile?id=~Wei_Zhang44" target="_blank" style="color: var(--primary-color);">Wei Zhang</a>.</p>

                <p style="margin-top: 0.5rem;">My research focuses on medical AI: particularly medical image segmentation, medical vision-language models, and generative modeling, with the aim of translating advanced AI technology into real clinical practice.</p>
                
            </div>
        </section>

        <!-- News Section -->
        <section id="news" class="section loading">
            <h2><i class="fas fa-newspaper"></i>News</h2>
            <div id="news-content">
                <!-- News content will be loaded from JavaScript -->
            </div>
        </section>

        <!-- Publications Section -->
        <section id="publications" class="section loading">
            <h2><i class="fas fa-book"></i>Selected Publications (<a href="https://scholar.google.com/citations?user=UFBrJOAAAAAJ" target="_blank">All Publications</a>)</h2>
            <div id="publications-content">
                <!-- Publications content will be loaded from JavaScript -->
            </div>
        </section>

        <!-- Awards Section -->
        <section id="awards" class="section loading">
            <h2><i class="fas fa-trophy"></i>Awards</h2>
            <div id="awards-content">
                <!-- Awards content will be loaded from JavaScript -->
            </div>
        </section>

        <!-- Academic Activities Section -->
        <section id="academic-activities" class="section loading">
            <h2><i class="fas fa-users"></i>Academic Activities</h2>
            <div id="academic-activities-content">
                <!-- Academic activities content will be loaded from JavaScript -->
            </div>
        </section>

        <!-- Talks Section -->
        <section id="talks" class="section loading">
            <h2><i class="fas fa-microphone"></i>Talks</h2>
            <div id="talks-content">
                <!-- Talks content will be loaded from JavaScript -->
            </div>
        </section>
    </main>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>Last updated: <span id="last-updated">August 23, 2020</span></p>
            <!-- <p style="font-size: 0.875rem; color: #9ca3af; margin-top: 0.5rem;">
                Visitors since launch: <span id="visitor-counter">Loading...</span>
                <span style="font-size: 0.75rem; margin-left: 0.5rem;">(via ClustrMaps)</span>
                <span id="visitor-status" style="font-size: 0.7rem; margin-left: 0.5rem; opacity: 0.7;"></span>
            </p> -->
        </div>
    </footer>

    <!-- Configuration and Scripts -->
    <script>
        // ============================================================================
        // WEBSITE CONTENT CONFIGURATION - EASY TO UPDATE SECTION
        // ============================================================================
        // 在这里更新你的网站内容，无需编辑HTML！
        // 只需要修改下面的数据，网站就会自动更新
        
        const siteConfig = {
            // 最后更新时间
            lastUpdated: "September 3, 2025",
            
            // 新闻动态
            news: [
                {
                    date: "2025.06",
                    text: "<p>One paper was accepted by <strong>ICCV 2025</strong>.</p><p style='font-size: 0.8em'>The paper focuses on ophthalmic surgical video-language pretraining. Grateful to all collaborators.</p>"
                },
                {
                    date: "2025.06",
                    text: "<p>Four papers were accepted by <strong>MICCAI 2025</strong>.</p><p style='font-size: 0.8em'>Two first-author papers cover MS lesion segmentation and polyp segmentation. Two co-authored papers focus on fundus image generation and interpretable counterfactual generation.</p>"
                },
                {
                    date: "2025.06",
                    text: "<p><a href='https://era-ai-biomed.github.io/GAIA/' target='_blank' style='color: var(--primary-color);'>GAIA Workshop</a> has been accepted at <strong>ICCV 2025</strong>.</p><p style='font-size: 0.8em'>The workshop explores how generative AI is reshaping biomedical image analysis across three critical areas: (1) Data Synthesis and Clinical Modeling; (2) Multimodal Learning; (3) Workflow Automation. We hope to bring together leading researchers to explore the future of generative AI for medical imaging.</p>"
                },
                {
                    date: "2025.02",
                    text: "<p>Two papers were accepted by <strong>CVPR 2025</strong>.</p><p style='font-size: 0.8em'>One paper is about interactive medical image segmentation with a new released large scale dataset, IMed-316M. The other presents SlideChat for gigapixel whole-slide images, plus SlideInstruction and SlideBench to support and evaluate MLLM-based pathology. Thanks to all collaborators.</p>"
                },
                {
                    date: "2024.12",
                    text: "<p><a href='https://www.codabench.org/competitions/4779/' target='_blank' style='color: var(--primary-color);'>FUGC ISBI 2025 Challenge</a> was launched.</p><p style='font-size: 0.8em'>The Fetal Ultrasound Grand Challenge (FUGC) aims to improve clinical decisions by making diagnostic tools more accessible and more accurate. It also hopes to advance machine learning for medical image analysis in settings with limited resources. <a href='https://www.codabench.org/competitions/4779/' target='_blank' style='color: var(--primary-color);'>Join here</a>.</p>"
                },
                {
                    date: "2024.09",
                    text: "<p>One paper was accepted by <strong>NeurIPS 2024</strong>.</p><p style='font-size: 0.8em'>As the project leader, we released GMAI-MMBench, the most comprehensive general medical AI benchmark, featuring a well-categorized data structure and multi-perceptual granularity.</p>"
                }
            ],
            
            // 论文发表
            publications: [
                {
                    title: "New Multiple Sclerosis Lesion Segmentation via Calibrated Inter-patch Blending",
                    authors: "<strong>Jin Ye</strong>, Son Duy Dao, Yicheng Wu, Yasmeen George, Thanh Nguyen-Duc, Daniel F. Schmidt, Hengcan Shi, Winston Chong, and Jianfei Cai",
                    venue: "MICCAI 2025",
                    links: [
                        { text: "Code", url: "https://github.com/Yejin0111/CIB" }
                    ]
                },
                {
                    title: "FPN-in-FPN: A Nested Multi-Scale Aggregation Network for Polyp Segmentation",
                    authors: "<strong>Jin Ye</strong>, Yanzhou Su, Yicheng Wu, Junjun He, Bohan Zhuang, Zhaolin Chen, and Jianfei Cai",
                    venue: "MICCAI 2025",
                    links: [
                        { text: "Code", url: "https://github.com/Yejin0111/FPN-in-FPN" },
                    ]
                },
                {
                    title: "Towards Interpretable Counterfactual Generation via Multimodal Autoregression",
                    authors: "Chenglong Ma, Yuanfeng Ji, <strong>Jin Ye</strong>, Lu Zhang, Ying Chen, Tianbin Li, Mingjie Li, Junjun He, and Hongming Shan",
                    venue: "MICCAI 2025",
                    links: [
                        { text: "Paper", url: "https://arxiv.org/pdf/2503.23149" },
                        { text: "Project", url: "https://progemu.github.io/" },
                        { text: "Code", url: "https://github.com/Masaaki-75/progemu" },
                    ]
                },
                {
                    title: "RetinaLogos: Fine-Grained Synthesis of High-Resolution Retinal Images Through Captions",
                    authors: "Junzhi Ning, Cheng Tang, Kaijing Zhou, Diping Song, Lihao Liu, Ming Hu, Wei Li, Huihui Xu, Yanzhou Su, Tianbin Li, Jiyao Liu, <strong>Jin Ye</strong>, Sheng Zhang, Yuanfeng Ji, and Junjun He",
                    venue: "MICCAI 2025",
                    links: [
                        { text: "Paper", url: "https://arxiv.org/pdf/2505.12887" },
                        { text: "Code", url: "https://github.com/uni-medical/retina-text2cfp" }
                    ]
                },
                {
                    title: "A-Eval: A benchmark for cross-dataset and cross-modality evaluation of abdominal multi-organ segmentation",
                    authors: "Ziyan Huang*, Zhongying Deng*, <strong>Jin Ye</strong>*, Haoyu Wang*, Yanzhou Su, Tianbin Li, Hui Sun, Junlong Cheng, Jianpin Chen, Junjun He, Yun Gu, Shaoting Zhang, Lixu Gu, and Yu Qiao",
                    venue: "Medical Image Analysis 2025",
                    links: [
                        { text: "Paper", url: "https://www.sciencedirect.com/science/article/abs/pii/S1361841525000477" },
                        { text: "Code", url: "https://github.com/uni-medical/A-Eval" }
                    ]
                },
                {
                    title: "Interactive Medical Image Segmentation: A Benchmark Dataset and Baseline",
                    authors: "Junlong Cheng, Bin Fu, <strong>Jin Ye</strong>, Guoan Wang, Tianbin Li, Haoyu Wang, Ruoyu Li, He Yao, Junren Cheng, JingWen Li, Yanzhou Su, Min Zhu, and Junjun He",
                    venue: "CVPR 2025",
                    links: [
                        { text: "Paper", url: "https://openaccess.thecvf.com/content/CVPR2025/papers/Cheng_Interactive_Medical_Image_Segmentation_A_Benchmark_Dataset_and_Baseline_CVPR_2025_paper.pdf" },
                        { text: "Project", url: "https://uni-medical.github.io/IMIS-Benchmark/" },
                        { text: "Code", url: "https://github.com/uni-medical/IMIS-Bench" },
                        { text: "Data", url: "https://huggingface.co/datasets/General-Medical-AI/IMed-361M" }
                    ]
                },
                {
                    title: "SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding",
                    authors: "Ying Chen, Guoan Wang, Yuanfeng Ji, Yanjun Li, <strong>Jin Ye</strong>, Tianbin Li, Ming Hu, Rongshan Yu, Yu Qiao, and Junjun He",
                    venue: "CVPR 2025",
                    links: [
                        { text: "Paper", url: "https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_SlideChat_A_Large_Vision-Language_Assistant_for_Whole-Slide_Pathology_Image_Understanding_CVPR_2025_paper.pdf" },
                        { text: "Project", url: "https://uni-medical.github.io/SlideChat.github.io/" },
                        { text: "Code", url: "https://github.com/uni-medical/SlideChat" },
                        { text: "Data", url: "https://huggingface.co/datasets/General-Medical-AI/SlideChat" }
                    ]
                },
                {
                    title: "SAM-Med3D: Towards General-Purpose Segmentation Models for Volumetric Medical Images",
                    authors: "Haoyu Wang, Sizheng Guo, <strong>Jin Ye</strong>, Zhongying Deng, Junlong Cheng, Tianbin Li, Jianpin Chen, Yanzhou Su, Ziyan Huang, Yiqing Shen, Bin Fu, Shaoting Zhang, Junjun He, and Yu Qiao",
                    venue: "ECCVW 2025",
                    links: [
                        { text: "Paper", url: "https://link.springer.com/chapter/10.1007/978-3-031-91721-9_4" },
                        { text: "Code", url: "https://github.com/uni-medical/SAM-Med3D" },
                        { text: "Data", url: "https://huggingface.co/datasets/blueyo0/SA-Med3D-140K" }
                    ]
                },
                {
                    title: "GMAI-MMBench: A Comprehensive Multimodal Evaluation Benchmark Towards General Medical AI",
                    authors: "Pengcheng Chen*, <strong>Jin Ye</strong>*†, Guoan Wang, Yanjun Li, Zhongying Deng, Wei Li, Tianbin Li, Haodong Duan, Ziyan Huang, Yanzhou Su, Benyou Wang, Shaoting Zhang, Bin Fu, Jianfei Cai, Bohan Zhuang, Eric J Seibel, Yu Qiao, and Junjun He",
                    venue: "NeurIPS 2024",
                    links: [
                        { text: "Paper", url: "https://proceedings.neurips.cc/paper_files/paper/2024/file/ab7e02fd60e47e2a379d567f6b54f04e-Paper-Datasets_and_Benchmarks_Track.pdf" },
                        { text: "Project", url: "https://uni-medical.github.io/GMAI-MMBench.github.io/#2023xtuner" },
                        { text: "Code", url: "https://github.com/uni-medical/GMAI-MMBench" },
                        { text: "Data", url: "https://huggingface.co/datasets/OpenGVLab/GMAI-MMBench" }
                    ]
                },
                {
                    title: "Results from the autoPET challenge on fully automated lesion segmentation in oncologic PET/CT imaging",
                    authors: "Sergios Gatidis, Marcel Früh, Matthias P Fabritius, Sijing Gu, Konstantin Nikolaou, Christian La Fougère, <strong>Jin Ye</strong>, Junjun He, Yige Peng, Lei Bi, Jun Ma, Bo Wang, Jia Zhang, Yukun Huang, Lars Heiliger, Zdravko Marinov, Rainer Stiefelhagen, Jan Egger, Jens Kleesiek, Ludovic Sibille, Lei Xiang, Simone Bendazzoli, Mehdi Astaraki, Michael Ingrisch, Clemens C Cyran, and Thomas Küstner",
                    venue: "Nature Machine Intelligence 2024",
                    links: [
                        { text: "Paper", url: "https://www.nature.com/articles/s42256-024-00912-9" }
                    ]
                },
                {
                    title: "SAM-Med3D-MoE: Towards a Non-Forgetting Segment Anything Model via Mixture of Experts for 3D Medical Image Segmentation",
                    authors: "Guoan Wang*, <strong>Jin Ye</strong>*, Junlong Cheng, Tianbin Li, Zhaolin Chen, Jianfei Cai, Junjun He, and Bohan Zhuang",
                    venue: "MICCAI 2024",
                    links: [
                        { text: "Paper", url: "https://link.springer.com/chapter/10.1007/978-3-031-72114-4_53" }
                    ]
                },
                {
                    title: "SA-Med2D-20M Dataset: Segment Anything in 2D Medical Imaging with 20 Million masks",
                    authors: "<strong>Jin Ye</strong>, Junlong Cheng, Jianpin Chen, Zhongying Deng, Tianbin Li, Haoyu Wang, Yanzhou Su, Ziyan Huang, Jilong Chen, Lei Jiang, Hui Sun, Min Zhu, Shaoting Zhang, Junjun He, and Yu Qiao",
                    venue: "arXiv",
                    links: [
                        { text: "Paper", url: "https://arxiv.org/pdf/2311.11969" },
                        { text: "Code", url: "https://github.com/OpenGVLab/SAM-Med2D" }
                    ]
                },
                {
                    title: "Revisiting Feature Propagation and Aggregation in Polyp Segmentation",
                    authors: "Yanzhou Su, Yiqing Shen, <strong>Jin Ye</strong>, Junjun He, and Jian Cheng",
                    venue: "MICCAI 2023",
                    links: [
                        { text: "Paper", url: "https://link.springer.com/chapter/10.1007/978-3-031-43904-9_61" }
                    ]
                },
                {
                    title: "STU-Net: Scalable and Transferable Medical Image Segmentation Models Empowered by Large-Scale Supervised Pre-training",
                    authors: "Ziyan Huang*, Haoyu Wang*, Zhongying Deng*, <strong>Jin Ye</strong>*, Yanzhou Su, Hui Sun, Junjun He, Yun Gu, Lixu Gu, Shaoting Zhang, and Yu Qiao",
                    venue: "arXiv",
                    links: [
                        { text: "Paper", url: "https://arxiv.org/pdf/2304.06716" },
                        { text: "Code", url: "https://github.com/uni-medical/STU-Net" }
                    ]
                },
                {
                    title: "SAM-Med2D",
                    authors: "Junlong Cheng*, <strong>Jin Ye</strong>*, Zhongying Deng, Jianpin Chen, Tianbin Li, Haoyu Wang, Yanzhou Su, Ziyan Huang, Jilong Chen, Lei Jiang, Hui Sun, Junjun He, Shaoting Zhang, Min Zhu, and Yu Qiao",
                    venue: "arXiv",
                    links: [
                        { text: "Paper", url: "https://arxiv.org/pdf/2308.16184" },
                        { text: "Code", url: "https://github.com/OpenGVLab/SAM-Med2D" }
                    ]
                },
                {
                    title: "Box-Grained Reranking Matching for Multi-Camera Multi-Target Tracking",
                    authors: "Xipeng Yang*, <strong>Jin Ye</strong>*†, Jincheng Lu, Chenting Gong, Minyue Jiang, Xiangru Lin, Wei Zhang, Xiao Tan, Yingying Li, Xiaoqing Ye, and Errui Ding",
                    venue: "CVPRW 2022",
                    links: [
                        { text: "Paper", url: "https://openaccess.thecvf.com/content/CVPR2022W/AICity/papers/Yang_Box-Grained_Reranking_Matching_for_Multi-Camera_Multi-Target_Tracking_CVPRW_2022_paper.pdf" },
                        { text: "Code", url: "https://github.com/Yejin0111/AICITY2022-Track1-MTMC" }
                    ]
                },
                {
                    title: "Group Shift Pointwise Convolution for Volumetric Medical Image Segmentation",
                    authors: "Junjun He*, <strong>Jin Ye</strong>*, Cheng Li, Diping Song, Wanli Chen, Shanshan Wang, Lixu Gu, and Yu Qiao",
                    venue: "MICCAI 2021",
                    links: []
                },
                {
                    title: "Attention-Driven Dynamic GCN Network for Multi-Label Image Recognition",
                    authors: "<strong>Jin Ye</strong>, Junjun He, Xiaojiang Peng, Wenhao Wu, and Yu Qiao",
                    venue: "ECCV 2020",
                    links: [
                        { text: "Paper", url: "https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123660647.pdf" },
                        { text: "Code", url: "https://github.com/Yejin0111/ADD-GCN" }
                    ]
                }
                // {
                //     title: "Dense correlation network for automatic ocular multi-disease detection with paired color fundus photographs",
                //     authors: "Cheng Li*, <strong>Jin Ye</strong>*, Junjun He*, Shanshan Wang, Yu Qiao, and Lixu Gu",
                //     venue: "ISBI 2020",
                //     links: [
                //         { text: "Paper", url: "https://ieeexplore.ieee.org/document/9098340" }
                //     ]
                // },
                // {
                //     title: "Classification of ocular diseases employing attention-based unilateral and bilateral feature weighting and fusion",
                //     authors: "Junjun He*, Cheng Li*, <strong>Jin Ye</strong>*, Shanshan Wang, Yu Qiao, and Lixu Gu",
                //     venue: "ISBI 2020",
                //     links: [
                //         { text: "Paper", url: "https://ieeexplore.ieee.org/document/9098525" }
                //     ]
                // },
                // {
                //     title: "Visual-Textual Sentiment Analysis in Product Reviews",
                //     authors: "<strong>Jin Ye</strong>, Xiaojiang Peng, Yu Qiao, Hao Xing, Junli Li, and Rongrong Ji",
                //     venue: "ICIP 2019",
                //     links: [
                //         { text: "Paper", url: "https://ieeexplore.ieee.org/document/8802992" }
                //     ]
                // }
            ],
            
            // 比赛获奖
            contests: [
                {
                    title: "ATLAS Challenge: A Tumor and Liver Automatic Segmentation, MICCAI 2023",
                    description: "🏆 Rank: <a href='https://atlas-challenge.u-bourgogne.fr/leaderboard' target='_blank'>1st Place</a>"
                },
                {
                    title: "SPPIN Challenge: Surgical Planning in Pediatric Neuroblastoma, MICCAI 2023",
                    description: "🏆 Rank: <a href='https://sppin.grand-challenge.org/' target='_blank'>1st Place</a> (Team Blackbean)"
                },
                {
                    title: "Syn-ISS Challenge: Synthetic Data for Instrument Segmentation in Surgery, MICCAI 2023",
                    description: "🏆 Rank: <a href='https://www.synapse.org/Synapse:syn50908388/wiki/624050' target='_blank'>1st Place in Task 2</a> (Team GMAI)"
                },
                {
                    title: "BraTS Challenge: The International Brain Tumor Segmentation, MICCAI 2023",
                    description: "🥈 Rank: <a href='https://www.synapse.org/Synapse:syn51156910/wiki/627802' target='_blank'>2nd Place in Task 3</a>. 🥉 Rank: <a href='https://www.synapse.org/Synapse:syn51156910/wiki/627802' target='_blank'>3rd Place in Task 2</a>. 🥉 Rank: <a href='https://www.synapse.org/Synapse:syn51156910/wiki/627802' target='_blank'>3rd Place in Task 4</a>. (Team Blackbean)" 
                },
                {
                    title: "autoPET II Challenge: Automated Lesion Segmentation in Whole-Body PET/CT - Domain Generalization, MICCAI 2023",
                    description: "🥈 Rank: <a href='https://autopet-ii.grand-challenge.org/leaderboard/' target='_blank'>2nd Place in Category 1</a>. 🥈 Rank: <a href='https://autopet-ii.grand-challenge.org/leaderboard/' target='_blank'>2nd Place in Category 2</a>. (Team Blackbean)" 
                },
                {
                    title: "FLARE Challenge: Fast, Low-resource, and Accurate oRgan and Pan-cancer sEgmentation in Abdomen CT, MICCAI 2023",
                    description: "🥉 Rank: <a href='https://codalab.lisn.upsaclay.fr/competitions/12239#learn_the_details-awards' target='_blank'>3rd Place</a> (Team Blackbean)"
                },
                {
                    title: "SegRap2023 Challenge: Segmentation of OARs and GTV of NPC for Radiotherapy Planning, MICCAI 2023",
                    description: "🥉 Rank: <a href='https://segrap2023.grand-challenge.org/final-ranking/' target='_blank'>3rd Place in Task 1</a> (Team Yanzhou Su)"
                },
                {
                    title: "autoPET Challenge: Automated Lesion Segmentation in Whole-Body PET/CT, MICCAI 2022",
                    description: "🏆 Rank: <a href='https://autopet.grand-challenge.org/final-leaderboard/' target='_blank'>1st Place in Task 1</a> (Team Blackbean)"
                },
                {
                    title: "FLARE Challenge: Fast and Low-resource semi-supervised Abdominal oRgan sEgmentation in CT, MICCAI 2022",
                    description: "🏆 Rank: <a href='https://flare22.grand-challenge.org/awards/' target='_blank'>1st Place</a> (Team Blackbean)"
                },
                {
                    title: "AMOS Challenge: Multi-Modality Abdominal Multi-Organ Segmentation, MICCAI 2022",
                    description: "🥈 Rank: <a href='https://amos22.grand-challenge.org/final-ranking/' target='_blank'>2nd Place in Task II</a>. 🥉 Rank: <a href='https://amos22.grand-challenge.org/final-ranking/' target='_blank'>3rd Place in Task I</a>. (Team Blackbean)"
                },
                {
                    title: "The 6th AI City Challenge, CVPR 2022",
                    description: "🏆 Rank: <a href='https://www.aicitychallenge.org/2022-challenge-winners/' target='_blank'>1st Place in Track 1</a> (Team28 matcher)"
                },
                {
                    title: "The 5th AI City Challenge, CVPR 2021",
                    description: "🥈 Rank: <a href='https://www.aicitychallenge.org/2021-challenge-winners/' target='_blank'>2nd Place in Track 3</a> (Team29 fivefive)"
                },
                {
                    title: "ODIR-2019 Challenge: Peking University International Competition on Ocular Disease Intelligent Recognition",
                    description: "🏆 Rank: <a href='https://odir2019.grand-challenge.org/' target='_blank'>1st Place</a>"
                }
                // {
                //     title: "Tianchi Competition on Fashion AI Global Challenge",
                //     description: "Rank: 5/3000+"
                // },
                // {
                //     title: "The Electrician Mathematical Contest in Modeling",
                //     description: "National second prize"
                // }
            ],
            
            // 奖学金和奖项
            awards: [
                {
                    title: "National Encouragement Scholarship",
                    description: "2013, 2014"
                },
                // {
                //     title: "National Encouragement Scholarship",
                //     description: "2013"
                // }
            ],

            // 学术活动
            academicActivities: [
                {
                    title: "ICCV 2025 Workshop - GAIA 2025",
                    description: "Generative AI for Biomedical Image Analysis: Opportunities, Challenges and Futures",
                    url: "https://era-ai-biomed.github.io/GAIA/"
                },
                {
                    title: "ISBI 2025 Challenge - FUGC 2025",
                    description: "Fetal Ultrasound Grand Challenge",
                    url: "https://www.codabench.org/competitions/4779/"
                },
                {
                    title: "MICCAI 2023 Workshop - MedAGI 2023",
                    description: "International Workshop on Foundation Models for General Medical AI",
                    url: "https://medagi2023.github.io/#/2023/organization"
                },
            ],

            // 学术报告
            talks: [
                {
                    title: "ExtremeMart",
                    description: "Academic presentation and discussion",
                    url: "https://mp.weixin.qq.com/s/t7O_BAGeYAH4as1snu2vRQ"
                }
            ]
        };

        // ============================================================================
        // 渲染函数 - 无需修改
        // ============================================================================

        function renderNews() {
            const container = document.getElementById('news-content');
            if (!siteConfig.news || siteConfig.news.length === 0) {
                container.innerHTML = '<p style="color: var(--text-secondary);">No news available at the moment.</p>';
                return;
            }
            
            container.innerHTML = siteConfig.news.map(item => `
                <div class="news-item">
                    <div class="news-date">${item.date}</div>
                    <div class="news-text">${item.text}</div>
                </div>
            `).join('');
        }

        function renderPublications() {
            const container = document.getElementById('publications-content');
            if (!siteConfig.publications || siteConfig.publications.length === 0) {
                container.innerHTML = '<p style="color: var(--text-secondary);">No publications available at the moment.</p>';
                return;
            }
            
            container.innerHTML = siteConfig.publications.map(pub => `
                <div class="publication">
                    <div class="publication-content">
                        <div class="publication-title">${pub.title}</div>
                        <div class="publication-authors">${pub.authors}</div>
                        <div class="publication-links">
                            <span class="publication-venue" style="font-size: 0.6rem;">${pub.venue}</span>
                            ${pub.links ? pub.links.map(link => `
                                <a href="${link.url}" target="_blank" class="publication-link" style="font-size: 0.6rem;">
                                    ${link.text}
                                </a>
                            `).join('') : ''}
                        </div>
                    </div>
                </div>
            `).join('');
        }

        function renderAwards() {
            const container = document.getElementById('awards-content');
            if ((!siteConfig.contests || siteConfig.contests.length === 0) && 
                (!siteConfig.awards || siteConfig.awards.length === 0)) {
                container.innerHTML = '<p style="color: var(--text-secondary);">No awards available at the moment.</p>';
                return;
            }
            
            let content = '';
            
            // Render contests first
            if (siteConfig.contests && siteConfig.contests.length > 0) {
                content += siteConfig.contests.map(contest => `
                    <div class="contest-item">
                        <div class="contest-icon">
                            <i class="fas fa-trophy"></i>
                        </div>
                        <div class="contest-content">
                            <div class="contest-title">${contest.title}</div>
                            <div class="contest-description">${contest.description}</div>
                        </div>
                    </div>
                `).join('');
            }
            
            // Render awards
            if (siteConfig.awards && siteConfig.awards.length > 0) {
                content += siteConfig.awards.map(award => `
                    <div class="award-item">
                        <div class="award-icon">
                            <i class="fas fa-medal"></i>
                        </div>
                        <div class="award-content">
                            <div class="award-title">${award.title}</div>
                            <div class="contest-description">${award.description}</div>
                        </div>
                    </div>
                `).join('');
            }
            
            container.innerHTML = content;
        }

        function renderAcademicActivities() {
            const container = document.getElementById('academic-activities-content');
            if (!siteConfig.academicActivities || siteConfig.academicActivities.length === 0) {
                container.innerHTML = '<p style="color: var(--text-secondary);">No academic activities available at the moment.</p>';
                return;
            }
            
            container.innerHTML = siteConfig.academicActivities.map(activity => `
                <div class="award-item">
                    <div class="award-icon">
                        ${activity.title.includes('Workshop') ? '<i class="fas fa-chalkboard-teacher"></i>' : 
                          activity.title.includes('Challenge') ? '<i class="fas fa-trophy"></i>' : 
                          '<i class="fas fa-users"></i>'}
                    </div>
                    <div class="award-content">
                        <div class="award-title">${activity.title}</div>
                        <div class="award-description">${activity.description}</div>
                        <div style="margin-top: 0.5rem;">
                            <a href="${activity.url}" target="_blank" class="publication-link">
                                <i class="fas fa-globe"></i>Visit Website
                            </a>
                        </div>
                    </div>
                </div>
            `).join('');
        }

        function renderTalks() {
            const container = document.getElementById('talks-content');
            if (!siteConfig.talks || siteConfig.talks.length === 0) {
                container.innerHTML = '<p style="color: var(--text-secondary);">No talks available at the moment.</p>';
                return;
            }
            
            container.innerHTML = siteConfig.talks.map(talk => `
                <div class="award-item">
                    <div class="award-icon">
                        <i class="fas fa-microphone"></i>
                    </div>
                    <div class="award-content">
                        <div class="award-title">${talk.title}</div>
                        <div class="award-description">${talk.description}</div>
                        <div style="margin-top: 0.5rem;">
                            <a href="${talk.url}" target="_blank" class="publication-link">
                                <i class="fas fa-play-circle"></i>View Details
                            </a>
                        </div>
                    </div>
                </div>
            `).join('');
        }

        // Navigation functionality
        function setupNavigation() {
            const navItems = document.querySelectorAll('.nav-item');
            const sections = document.querySelectorAll('section[id]');

            navItems.forEach(item => {
                item.addEventListener('click', (e) => {
                    e.preventDefault();
                    const targetId = item.getAttribute('href').substring(1);
                    
                    // Update active nav item
                    navItems.forEach(nav => nav.classList.remove('active'));
                    item.classList.add('active');
                    
                    // Scroll to section
                    document.getElementById(targetId).scrollIntoView({
                        behavior: 'smooth'
                    });
                });
            });

            // Update active nav item on scroll
            window.addEventListener('scroll', () => {
                let current = '';
                sections.forEach(section => {
                    const sectionTop = section.offsetTop;
                    const sectionHeight = section.clientHeight;
                    if (window.pageYOffset >= sectionTop - 200) {
                        current = section.getAttribute('id');
                    }
                });

                navItems.forEach(item => {
                    item.classList.remove('active');
                    if (item.getAttribute('href') === `#${current}`) {
                        item.classList.add('active');
                    }
                });
            });
        }

        // // ClustrMaps visitor counter - Real-time updates
        // async function initVisitorCounter() {
        //     const statusElement = document.getElementById('visitor-status');
        //     const counterElement = document.getElementById('visitor-counter');
            
        //     try {
        //         statusElement.textContent = 'Updating...';
        //         // Try to fetch real-time data from ClustrMaps
        //         const response = await fetch('https://clustrmaps.com/site/1bcjt');
        //         if (response.ok) {
        //             const data = await response.json();
        //             const realCount = data.total_visitors || data.visitors || 4399;
        //             counterElement.textContent = realCount.toLocaleString();
        //             statusElement.textContent = 'Live';
        //             setTimeout(() => {
        //                 statusElement.textContent = '';
        //             }, 2000);
        //         } else {
        //             // Fallback to cached data if API fails
        //             const fallbackCount = 4399;
        //             counterElement.textContent = fallbackCount.toLocaleString();
        //             statusElement.textContent = ''; // Cached
        //             setTimeout(() => {
        //                 statusElement.textContent = '';
        //             }, 2000);
        //         }
        //     } catch (error) {
        //         console.log('Using fallback visitor count');
        //         // Fallback to cached data if network error
        //         const fallbackCount = 4399;
        //         counterElement.textContent = fallbackCount.toLocaleString();
        //         statusElement.textContent = 'Offline';
        //         setTimeout(() => {
        //             statusElement.textContent = '';
        //         }, 2000);
        //     }
        // }

        // // Update visitor count periodically
        // function startVisitorCountUpdates() {
        //     // Update every 5 minutes
        //     setInterval(initVisitorCounter, 5 * 60 * 1000);
        // }

        // Initialize the page
        function init() {
            // Render all content
            renderNews();
            renderPublications();
            renderAwards();
            renderAcademicActivities();
            renderTalks();
            
            // Setup navigation
            setupNavigation();
            
            // Update last updated date
            if (siteConfig.lastUpdated) {
                document.getElementById('last-updated').textContent = siteConfig.lastUpdated;
            }
            
            // Initialize visitor counter
            initVisitorCounter();
            
            // Start visitor count updates
            startVisitorCountUpdates();
            
            console.log('Website loaded successfully!');
        }

        // Load the page when DOM is ready
        document.addEventListener('DOMContentLoaded', init);
    </script>
</body>
</html>
